{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from sys import maxsize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sign of learningRate determines whether to use gradient ascent/descent:\n",
    "Negative learningRates = descent, positive = ascent\n",
    "\"\"\"\n",
    "def SGO(x, y, seed, gradientFunc, learningRate, error, maxIter):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Reshape 1-D arrays to column format\n",
    "    # if len(x.shape) == 1:\n",
    "    #     x = x.reshape(-1, 1)\n",
    "\n",
    "    N = len(x)\n",
    "    currentError = maxsize\n",
    "    lastError = 0\n",
    "    beta = np.array(seed)\n",
    "#     print('SGO weight shape:', beta.shape)\n",
    "    i = 0\n",
    "\n",
    "    while i < maxIter:\n",
    "        gradient = gradientFunc(beta, x, y)\n",
    "#         yPredicted = x.dot(beta)\n",
    "#         sqErrGradient = np.array(np.dot(x.T, (yPredicted - y)) / N)\n",
    "        beta += learningRate * gradient\n",
    "#         currentError = np.sum(np.square(y - yPredicted)) / N\n",
    "        currentError = np.sum(gradient)\n",
    "#         print(currentError)\n",
    "\n",
    "        if abs(lastError - currentError) < error:\n",
    "            break\n",
    "        lastError = currentError\n",
    "        i += 1\n",
    "\n",
    "    return beta\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dSigmoid(y):\n",
    "    return y * (1.0 - y)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dTanh(y):\n",
    "    return 1 - y * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    inputNeurons: number of input neurons\n",
    "    hiddenLayerShape: (number of layers, number of neurons per layer) tuple\n",
    "    outputNeurons: number of output neurons\n",
    "    \"\"\"\n",
    "    def __init__(self, inputNeurons, hiddenLayerShape, outputNeurons,\n",
    "                 learnRate=1e-3, T=1, sigmoid=sigmoid, dSigmoid=dSigmoid):\n",
    "        self.inputNeurons = inputNeurons + 1\n",
    "        self.hiddenLayerShape = hiddenLayerShape\n",
    "        self.outputNeurons = outputNeurons\n",
    "        self.T = T\n",
    "        self.sigmoid = sigmoid\n",
    "        self.dSigmoid = dSigmoid\n",
    "        hiddenLayers, hiddenNeurons = hiddenLayerShape\n",
    "        \n",
    "        input_range = 1.0 / self.inputNeurons ** (1/2)\n",
    "        output_range = 1.0 / hiddenNeurons ** (1/2)\n",
    "        self.w_input = np.random.normal(loc=0, scale=input_range,\n",
    "                                   size=(self.inputNeurons, hiddenNeurons))\n",
    "        self.w_hidden = np.random.normal(loc=0, scale=output_range,\n",
    "                                        size=(hiddenLayers, hiddenNeurons, hiddenNeurons))\n",
    "        self.w_output = np.random.normal(loc=0, scale=output_range,\n",
    "                                   size=(hiddenNeurons, self.outputNeurons))\n",
    "        \n",
    "        self.a_input = np.ones(self.inputNeurons, dtype=float)\n",
    "        self.a_hidden = np.ones(shape=(hiddenLayers, hiddenNeurons), dtype=float)\n",
    "        self.a_output = np.ones(self.outputNeurons, dtype=float)\n",
    "        \n",
    "#         print('Input weights:', self.w_input)\n",
    "#         print('Hidden weights:', self.w_hidden)\n",
    "#         print('Output weights:', self.w_output)\n",
    "        \n",
    "        self.c_input = np.zeros(shape=(self.inputNeurons, hiddenNeurons), dtype=float)\n",
    "        self.c_hidden = np.zeros(shape=(hiddenLayers, hiddenNeurons, hiddenNeurons), dtype=float)\n",
    "        self.c_output = np.zeros(shape=(hiddenNeurons, self.outputNeurons), dtype=float)\n",
    "        \n",
    "        self.learnRate = learnRate\n",
    "        self._currentLearnRate = learnRate\n",
    "    \n",
    "    def fit(self, x, y, iterations=100):\n",
    "        stepSize = step = len(x) // 10\n",
    "        xy = list(zip(x, y))\n",
    "        self._currentLearnRate = self.learnRate\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            random.shuffle(xy)\n",
    "            error = 0.0\n",
    "            for xVal, yVal in xy:\n",
    "                self._feedForward(xVal)\n",
    "                error = self._backPropagate(yVal)\n",
    "            if i == step:\n",
    "                print('Error={}, current learning rate={}'.format(\n",
    "                        error, self._currentLearnRate))\n",
    "                step += stepSize\n",
    "            \n",
    "            self._currentLearnRate = self.learnRate / (1 + (i / self.T))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions = []\n",
    "        for xVal in x:\n",
    "            predict = self._feedForward(xVal)\n",
    "            predict[np.argmax(predict)] = 1\n",
    "            predict[predict < 1.0] = 0\n",
    "            print(predict)\n",
    "            predictions.append(predict)\n",
    "        return np.array(predictions, dtype=int)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        if type(x) != np.ndarray:\n",
    "            x = np.array(x)\n",
    "        if type(y) != np.ndarray:\n",
    "            y = np.array(y)\n",
    "            \n",
    "        correct = 0\n",
    "        predictions = self.predict(x)\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            y, predictions, average='macro')\n",
    "        \n",
    "        for prediction, yTruth in zip(predictions, y):\n",
    "            if np.array_equal(prediction, yTruth):\n",
    "                correct += 1\n",
    "                \n",
    "        accuracy = correct / len(y)\n",
    "#         print('Predictions:', predictions)\n",
    "#         print('Truth:', y)\n",
    "        \n",
    "        return accuracy, precision, recall, f1\n",
    "    \n",
    "    def _feedForward(self, x):\n",
    "        if type(x) != np.ndarray:\n",
    "            x = np.array(x)\n",
    "        \n",
    "        self.a_input[:-1] = x\n",
    "#         for i in range(len(self.a_input) - 1):\n",
    "#             self.a_input[i] = self.w_input[i]\n",
    "#         print('Input activation:', self.a_input)\n",
    "        hiddenLayers, hiddenNeurons = self.hiddenLayerShape\n",
    "#         print(self.w_hidden[0])\n",
    "        \n",
    "        if hiddenLayers > 0:\n",
    "#             self.a_hidden[0] = sigmoid(self.a_input * self.w_input)\n",
    "            for j in range(hiddenNeurons):\n",
    "                activation = 0.0\n",
    "                \n",
    "                for i in range(self.inputNeurons):\n",
    "                    activation += self.a_input[i] * self.w_input[i][j]\n",
    "                self.a_hidden[0][j] = tanh(activation)\n",
    "        \n",
    "            for layer in range(1, hiddenLayers):\n",
    "                for j in range(hiddenNeurons):\n",
    "                    activation = 0.0\n",
    "\n",
    "                    for i in range(hiddenNeurons):\n",
    "#                         print('A_Hidden[{}][{}] len={}'.format(layer, i, len(self.a_hidden[layer][i])))\n",
    "                        activation += self.a_hidden[layer][i] * self.w_hidden[layer][i][j]\n",
    "                    self.a_hidden[layer][j] = tanh(activation)\n",
    "#         print('Hidden activations:', self.a_hidden)\n",
    "#         print('Output weights:', self.w_output)\n",
    "#         print('Final hidden activations:', self.a_hidden[-1][0])\n",
    "#         print('Final hidden activation weighted sums:', np.sum())\n",
    "#         print('w_output[0]:', self.w_output[0])\n",
    "        \n",
    "        for k in range(self.outputNeurons):\n",
    "            activation = 0.0\n",
    "            \n",
    "#             self.a_output = sigmoid(np.sum(self.a_hidden[-1] * self.w_output[:][k], axis=0))\n",
    "            for j in range(hiddenNeurons):\n",
    "                activation += self.a_hidden[-1][j] * self.w_output[j][k]\n",
    "            \n",
    "            self.a_output[k] = sigmoid(activation)\n",
    "#         print('Output activations:', self.a_output)\n",
    "        return self.a_output[:]\n",
    "    \n",
    "    \"\"\"\n",
    "    Update weights and return the current error\n",
    "    @param y must be one-hot encoded representation of class\n",
    "    \"\"\"\n",
    "    def _backPropagate(self, y):\n",
    "        if type(y) != np.ndarray:\n",
    "            y = np.array(y)\n",
    "        \n",
    "        outputDeltas = self.dSigmoid(self.a_output) * (self.a_output - y)\n",
    "#         print('Output deltas:', outputDeltas)\n",
    "        \n",
    "        hiddenLayers, hiddenNeurons = self.hiddenLayerShape\n",
    "        hiddenDeltas = np.zeros(shape=self.a_hidden.shape, dtype=float)\n",
    "#         print('Hidden deltas:', hiddenDeltas)\n",
    "#         print('Last hidden deltas:', hiddenDeltas[-1])\n",
    "        \n",
    "        for j in range(hiddenNeurons):\n",
    "            error = np.sum(outputDeltas * self.w_output[j])\n",
    "            hiddenDeltas[-1][j] = dTanh(self.a_hidden[-1][j]) * error\n",
    "#         print('Hidden deltas from output error:', hiddenDeltas)\n",
    "        \n",
    "        for j in range(hiddenNeurons):\n",
    "            change = outputDeltas * self.a_hidden[-1][j]\n",
    "            self.w_output[j] -= self._currentLearnRate * change + self.c_output[j]\n",
    "            self.c_output[j] = change\n",
    "        \n",
    "#         print('C_Output:', self.c_output)\n",
    "        # TODO: Finish hidden layer error propagation for multiple hidden layers\n",
    "        for layer in reversed(range(hiddenLayers - 1)):\n",
    "            print('Backpropping through layer', layer)\n",
    "            error = np.sum(hiddenDeltas[layer + 1] * self.w_hidden[layer], axis=1)\n",
    "            hiddenDeltas[layer] = error\n",
    "#         print('Hidden deltas:', hiddenDeltas)\n",
    "        \n",
    "        for i in range(self.inputNeurons):\n",
    "            change = hiddenDeltas[0] * self.a_input[i]\n",
    "            self.w_input[i] -= self._currentLearnRate * change * self.c_input[i]\n",
    "            self.c_input[i] = change\n",
    "            \n",
    "#         print('C_Input:', self.c_input)\n",
    "        error = np.sum(0.5 * np.square(self.a_output - y))\n",
    "#         print('Overall error:', error)\n",
    "#         print('new learning rate:', self._currentLearnRate)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Malignancy of Breast Cancer Cases\n",
    "## Source: [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClumpThickness</th>\n",
       "      <th>CellSizeUniformity</th>\n",
       "      <th>CellShapeUniformity</th>\n",
       "      <th>MarginalAdhesion</th>\n",
       "      <th>SingleEpithelialCellSize</th>\n",
       "      <th>BlandChromatin</th>\n",
       "      <th>NormalNucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ClumpThickness  CellSizeUniformity  CellShapeUniformity  MarginalAdhesion  \\\n",
       "0               5                   1                    1                 1   \n",
       "1               5                   4                    4                 5   \n",
       "2               3                   1                    1                 1   \n",
       "3               6                   8                    8                 1   \n",
       "4               4                   1                    1                 3   \n",
       "\n",
       "   SingleEpithelialCellSize  BlandChromatin  NormalNucleoli  Mitoses  Class_2  \\\n",
       "0                         2               3               1        1        1   \n",
       "1                         7               3               2        1        1   \n",
       "2                         2               3               1        1        1   \n",
       "3                         3               3               7        1        1   \n",
       "4                         2               3               1        1        1   \n",
       "\n",
       "   Class_4  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% malignant 0.34992679355783307\n"
     ]
    }
   ],
   "source": [
    "breastCancerDf = pd.read_csv('data/breast-cancer-wisconsin.csv')\n",
    "breastCancerDf['Class_2'] = breastCancerDf.Class.apply(lambda x: 1 if x == 2 else 0)\n",
    "breastCancerDf['Class_4'] = breastCancerDf.Class.apply(lambda x: 1 if x == 4 else 0)\n",
    "breastCancerDf.drop(breastCancerDf[breastCancerDf['BareNuclei'] == '?'].index, inplace=True)\n",
    "yColumn = ['Class_2', 'Class_4']\n",
    "xColumns = [col for col in breastCancerDf.columns\n",
    "            if col != 'ID' and col not in yColumn\n",
    "           and col != 'BareNuclei' and col != 'Class']\n",
    "display(breastCancerDf[xColumns + yColumn].head())\n",
    "\n",
    "print('% malignant', len(breastCancerDf['Class'].loc[breastCancerDf['Class_4'] == 1]) / len(breastCancerDf['Class_4']))\n",
    "\n",
    "# Split into test and training sets\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(breastCancerDf[xColumns].as_matrix(),\n",
    "                                               breastCancerDf[yColumn].as_matrix(),\n",
    "                                               test_size=1/3, random_state=int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error=0.3910532404278619, current learning rate=0.0010417938465299898\n",
      "Error=0.300196586471274, current learning rate=0.0005208969232649949\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "[ 1.  0.]\n",
      "Accuracy: 0.6272, precision: 0.3136, recall: 0.5000, F1: 0.3854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(8, (1, 8), 2, learnRate=1/np.sqrt(xTrain.shape[0]))\n",
    "nn.fit(xTrain, yTrain)\n",
    "accuracy, precision, recall, f1 = nn.score(xTest, yTest)\n",
    "print('Accuracy: {:.4f}, precision: {:.4f}, recall: {:.4f}, F1: {:.4f}'.format(\n",
    "        accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
