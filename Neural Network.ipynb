{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from sys import maxsize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sign of learningRate determines whether to use gradient ascent/descent:\n",
    "Negative learningRates = descent, positive = ascent\n",
    "\"\"\"\n",
    "def SGO(x, y, seed, gradientFunc, learningRate, error, maxIter):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Reshape 1-D arrays to column format\n",
    "    # if len(x.shape) == 1:\n",
    "    #     x = x.reshape(-1, 1)\n",
    "\n",
    "    N = len(x)\n",
    "    currentError = maxsize\n",
    "    lastError = 0\n",
    "    beta = np.array(seed)\n",
    "#     print('SGO weight shape:', beta.shape)\n",
    "    i = 0\n",
    "\n",
    "    while i < maxIter:\n",
    "        gradient = gradientFunc(beta, x, y)\n",
    "#         yPredicted = x.dot(beta)\n",
    "#         sqErrGradient = np.array(np.dot(x.T, (yPredicted - y)) / N)\n",
    "        beta += learningRate * gradient\n",
    "#         currentError = np.sum(np.square(y - yPredicted)) / N\n",
    "        currentError = np.sum(gradient)\n",
    "#         print(currentError)\n",
    "\n",
    "        if abs(lastError - currentError) < error:\n",
    "            break\n",
    "        lastError = currentError\n",
    "        i += 1\n",
    "\n",
    "    return beta\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dSigmoid(y):\n",
    "    return y * (1.0 - y)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dTanh(y):\n",
    "    return 1 - y * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    inputNeurons: number of input neurons\n",
    "    hiddenLayerShape: (number of layers, number of neurons per layer) tuple\n",
    "    outputNeurons: number of output neurons\n",
    "    \"\"\"\n",
    "    def __init__(self, inputNeurons, hiddenLayerShape, outputNeurons,\n",
    "                 learnRate=1e-3, T=1, sigmoid=sigmoid, dSigmoid=dSigmoid):\n",
    "        self.inputNeurons = inputNeurons + 1\n",
    "        self.hiddenLayerShape = hiddenLayerShape\n",
    "        self.outputNeurons = outputNeurons\n",
    "        self.T = T\n",
    "        self.sigmoid = sigmoid\n",
    "        self.dSigmoid = dSigmoid\n",
    "        hiddenLayers, hiddenNeurons = hiddenLayerShape\n",
    "        \n",
    "        input_range = 1.0 / self.inputNeurons ** (1/2)\n",
    "        output_range = 1.0 / hiddenNeurons ** (1/2)\n",
    "        self.w_input = np.random.normal(loc=0, scale=input_range,\n",
    "                                   size=(self.inputNeurons, hiddenNeurons))\n",
    "        self.w_hidden = np.random.normal(loc=0, scale=output_range,\n",
    "                                        size=(hiddenLayers, hiddenNeurons, hiddenNeurons))\n",
    "        self.w_output = np.random.normal(loc=0, scale=output_range,\n",
    "                                   size=(hiddenNeurons, self.outputNeurons))\n",
    "        \n",
    "        self.a_input = np.ones(self.inputNeurons, dtype=float)\n",
    "        self.a_hidden = np.ones(shape=(hiddenLayers, hiddenNeurons), dtype=float)\n",
    "        self.a_output = np.ones(self.outputNeurons, dtype=float)\n",
    "        \n",
    "        print('Input weights:', self.w_input)\n",
    "        print('Hidden weights:', self.w_hidden)\n",
    "        print('Output weights:', self.w_output)\n",
    "        \n",
    "        self.c_input = np.zeros(shape=(self.inputNeurons, hiddenNeurons), dtype=float)\n",
    "        self.c_hidden = np.zeros(shape=(hiddenLayers, hiddenNeurons, hiddenNeurons), dtype=float)\n",
    "        self.c_output = np.zeros(shape=(hiddenNeurons, self.outputNeurons), dtype=float)\n",
    "        \n",
    "        self.learnRate = learnRate\n",
    "        self._currentLearnRate = learnRate\n",
    "    \n",
    "    def fit(self, x, y, iterations=100):\n",
    "        step = len(x) // 10\n",
    "        stepSize = step\n",
    "        xy = list(zip(x, y))\n",
    "        self._currentLearnRate = self.learnRate\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            random.shuffle(xy)\n",
    "            error = 0.0\n",
    "            for xVal, yVal in xy:\n",
    "                self._feedForward(xVal)\n",
    "                error = self._backPropagate(yVal)\n",
    "            if i == step:\n",
    "                print('Error={}, current learning rate={}'.format(\n",
    "                        error, self._currentLearnRate))\n",
    "                step += stepSize\n",
    "            \n",
    "            self._currentLearnRate = self.learnRate / (1 + (i / self.T))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions = []\n",
    "        for xVal in x:\n",
    "            predict = self._feedForward(xVal)\n",
    "            print(predict)\n",
    "            predict[np.argmax(predict)] = 1\n",
    "            predict[predict < 1.0] = 0\n",
    "            predictions.append(predict)\n",
    "        return np.array(predictions, dtype=int)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        if type(x) != np.ndarray:\n",
    "            x = np.array(x)\n",
    "        if type(y) != np.ndarray:\n",
    "            y = np.array(y)\n",
    "            \n",
    "        correct = 0\n",
    "        predictions = self.predict(x)\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(\n",
    "            y, predictions, average='micro')\n",
    "        \n",
    "        for prediction, yTruth in zip(predictions, y):\n",
    "            if np.array_equal(prediction, yTruth):\n",
    "                correct += 1\n",
    "                \n",
    "        accuracy = correct / len(y)\n",
    "#         print('Predictions:', predictions)\n",
    "#         print('Truth:', y)\n",
    "        \n",
    "        return accuracy, precision, recall, f1\n",
    "    \n",
    "    def _feedForward(self, x):\n",
    "        if type(x) != np.ndarray:\n",
    "            x = np.array(x)\n",
    "        \n",
    "        self.a_input[:-1] = x\n",
    "#         for i in range(len(self.a_input) - 1):\n",
    "#             self.a_input[i] = self.w_input[i]\n",
    "#         print('Input activation:', self.a_input)\n",
    "        hiddenLayers, hiddenNeurons = self.hiddenLayerShape\n",
    "#         print(self.w_hidden[0])\n",
    "        \n",
    "        if hiddenLayers > 0:\n",
    "#             self.a_hidden[0] = sigmoid(self.a_input * self.w_input)\n",
    "            for j in range(hiddenNeurons):\n",
    "                activation = 0.0\n",
    "                \n",
    "                for i in range(self.inputNeurons):\n",
    "                    activation += self.a_input[i] * self.w_input[i][j]\n",
    "                self.a_hidden[0][j] = self.sigmoid(activation)\n",
    "        \n",
    "            for layer in range(1, hiddenLayers):\n",
    "                for j in range(hiddenNeurons):\n",
    "                    activation = 0.0\n",
    "\n",
    "                    for i in range(hiddenNeurons):\n",
    "#                         print('A_Hidden[{}][{}] len={}'.format(layer, i, len(self.a_hidden[layer][i])))\n",
    "                        activation += self.a_hidden[layer][i] * self.w_hidden[layer][i][j]\n",
    "                    self.a_hidden[layer][j] = self.sigmoid(activation)\n",
    "#         print('Hidden activations:', self.a_hidden)\n",
    "#         print('Output weights:', self.w_output)\n",
    "#         print('Final hidden activations:', self.a_hidden[-1][0])\n",
    "#         print('Final hidden activation weighted sums:', np.sum())\n",
    "#         print('w_output[0]:', self.w_output[0])\n",
    "        \n",
    "        for k in range(self.outputNeurons):\n",
    "            activation = 0.0\n",
    "            \n",
    "#             self.a_output = sigmoid(np.sum(self.a_hidden[-1] * self.w_output[:][k], axis=0))\n",
    "            for j in range(hiddenNeurons):\n",
    "                activation += self.a_hidden[-1][j] * self.w_output[j][k]\n",
    "            \n",
    "            self.a_output[k] = self.sigmoid(activation)\n",
    "#         print('Output activations:', self.a_output)\n",
    "        return self.a_output[:]\n",
    "    \n",
    "    \"\"\"\n",
    "    Update weights and return the current error\n",
    "    @param y must be one-hot encoded representation of class\n",
    "    \"\"\"\n",
    "    def _backPropagate(self, y):\n",
    "        if type(y) != np.ndarray:\n",
    "            y = np.array(y)\n",
    "        \n",
    "        outputDeltas = self.dSigmoid(self.a_output) * (self.a_output - y)\n",
    "#         print('Output deltas:', outputDeltas)\n",
    "        \n",
    "        hiddenLayers, hiddenNeurons = self.hiddenLayerShape\n",
    "        hiddenDeltas = np.zeros(shape=self.a_hidden.shape, dtype=float)\n",
    "#         print('Hidden deltas:', hiddenDeltas)\n",
    "#         print('Last hidden deltas:', hiddenDeltas[-1])\n",
    "        \n",
    "        for j in range(hiddenNeurons):\n",
    "            error = np.sum(outputDeltas * self.w_output[j])\n",
    "            hiddenDeltas[-1][j] = self.dSigmoid(self.a_hidden[-1][j]) * error\n",
    "#         print('Hidden deltas from output error:', hiddenDeltas)\n",
    "        \n",
    "        for j in range(hiddenNeurons):\n",
    "            change = outputDeltas * self.a_hidden[-1][j]\n",
    "            self.w_output[j] -= self._currentLearnRate * change + self.c_output[j]\n",
    "            self.c_output[j] = change\n",
    "        \n",
    "#         print('C_Output:', self.c_output)\n",
    "        # TODO: Finish hidden layer error propagation for multiple hidden layers\n",
    "        for layer in reversed(range(hiddenLayers - 1)):\n",
    "            print('Backpropping through layer', layer)\n",
    "            error = np.sum(hiddenDeltas[layer + 1] * self.w_hidden[layer], axis=1)\n",
    "            hiddenDeltas[layer] = error\n",
    "#         print('Hidden deltas:', hiddenDeltas)\n",
    "        \n",
    "        for i in range(self.inputNeurons):\n",
    "            change = hiddenDeltas[0] * self.a_input[i]\n",
    "            self.w_input[i] -= self._currentLearnRate * change * self.c_input[i]\n",
    "            self.c_input[i] = change\n",
    "            \n",
    "#         print('C_Input:', self.c_input)\n",
    "        error = np.sum(0.5 * np.square(self.a_output - y))\n",
    "#         print('Overall error:', error)\n",
    "#         print('new learning rate:', self._currentLearnRate)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Malignancy of Breast Cancer Cases\n",
    "## Source: [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClumpThickness</th>\n",
       "      <th>CellSizeUniformity</th>\n",
       "      <th>CellShapeUniformity</th>\n",
       "      <th>MarginalAdhesion</th>\n",
       "      <th>SingleEpithelialCellSize</th>\n",
       "      <th>BlandChromatin</th>\n",
       "      <th>NormalNucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ClumpThickness  CellSizeUniformity  CellShapeUniformity  MarginalAdhesion  \\\n",
       "0               5                   1                    1                 1   \n",
       "1               5                   4                    4                 5   \n",
       "2               3                   1                    1                 1   \n",
       "3               6                   8                    8                 1   \n",
       "4               4                   1                    1                 3   \n",
       "\n",
       "   SingleEpithelialCellSize  BlandChromatin  NormalNucleoli  Mitoses  Class_2  \\\n",
       "0                         2               3               1        1        1   \n",
       "1                         7               3               2        1        1   \n",
       "2                         2               3               1        1        1   \n",
       "3                         3               3               7        1        1   \n",
       "4                         2               3               1        1        1   \n",
       "\n",
       "   Class_4  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% malignant 0.0\n"
     ]
    }
   ],
   "source": [
    "breastCancerDf = pd.read_csv('data/breast-cancer-wisconsin.csv')\n",
    "breastCancerDf['Class_2'] = breastCancerDf.Class.apply(lambda x: 1 if x == 2 else 0)\n",
    "breastCancerDf['Class_4'] = breastCancerDf.Class.apply(lambda x: 1 if x == 4 else 0)\n",
    "# breastCancerDf.loc[breastCancerDf['Class'] == 2, 'Class'] = 0\n",
    "# breastCancerDf.loc[breastCancerDf['Class'] == 4, 'Class'] = 1\n",
    "# breastCancerDf.drop('BareNuclei', axis=1)\n",
    "breastCancerDf.drop(breastCancerDf[breastCancerDf['BareNuclei'] == '?'].index, inplace=True)\n",
    "# yCols = pd.get_dummies(breastCancerDf, ['Class'])\n",
    "yColumn = ['Class_2', 'Class_4']\n",
    "xColumns = [col for col in breastCancerDf.columns\n",
    "            if col != 'ID' and col not in yColumn\n",
    "           and col != 'BareNuclei' and col != 'Class']\n",
    "display(breastCancerDf[xColumns + yColumn].head())\n",
    "\n",
    "print('% malignant', len(breastCancerDf['Class'].loc[breastCancerDf['Class'] == 1]) / len(breastCancerDf['Class']))\n",
    "\n",
    "# Split into test and training sets\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(breastCancerDf[xColumns].as_matrix(),\n",
    "                                               breastCancerDf[yColumn].as_matrix(),\n",
    "                                               test_size=1/3, random_state=int(time.time()))\n",
    "# np.random.seed(524)\n",
    "# trainProportion = 0.8\n",
    "# trainMask = np.random.rand(len(breastCancerDf)) < trainProportion\n",
    "# cancerTrainingDf = breastCancerDf[trainMask]\n",
    "# cancerTestDf = breastCancerDf[~trainMask].reset_index()\n",
    "# print('Total # cancer samples: {}, training samples: {}, test samples: {}'.format(\n",
    "#     len(breastCancerDf), len(cancerTrainingDf), len(cancerTestDf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input weights: [[ 0.73834445  0.07809863 -0.55970531 -0.3493896   0.43920094 -0.20476651\n",
      "   0.4689989   0.4724118 ]\n",
      " [ 0.66509989  0.50928829 -0.0668104  -0.65535882  0.11018331  0.41723637\n",
      "  -0.28042966 -0.49727329]\n",
      " [-0.2615342   0.09820532  0.19034924 -0.44885199  0.20762765 -0.30036944\n",
      "  -0.00352282 -0.10093826]\n",
      " [ 0.11605771 -0.24052416  0.33921815 -0.09775575 -0.55989699  0.17006471\n",
      "   0.18568275 -0.47637227]\n",
      " [-0.52870096  0.26787501  0.16841665 -1.04951386 -0.29925651 -0.22831395\n",
      "  -0.05808151  0.74919378]\n",
      " [-0.09309249  0.83864771 -0.2478754   0.64098049 -0.04801827 -0.19426168\n",
      "  -0.48479724  0.70630633]\n",
      " [ 0.43444632 -0.34054734  0.39873428 -0.34497676 -0.15636949 -0.16196999\n",
      "   0.0795606   0.45942067]\n",
      " [ 0.02400383  0.38273614 -0.00801556  0.46343198  0.2889736   0.05416576\n",
      "  -0.34337957  0.00538866]\n",
      " [ 0.17078634  0.44284145  0.07807196 -0.17992315  0.02463298 -0.17324059\n",
      "   0.53350778  0.0453778 ]]\n",
      "Hidden weights: [[[-0.26187937  0.40893067 -0.08276093  0.17433976 -0.41727759 -0.01744951\n",
      "    0.01400166  0.08009615]\n",
      "  [ 0.08880478 -0.10198887 -0.18258198 -0.4732003   0.22276114 -0.11117923\n",
      "   -0.02855044  0.92673175]\n",
      "  [ 0.06103076  0.4105391  -0.21917224  0.40474956  0.01320925  0.07286965\n",
      "    0.14178695  0.1830783 ]\n",
      "  [-0.12412447  0.35619341 -0.00421246 -0.54696757  0.24749016  0.60298398\n",
      "   -0.65377237  0.35903442]\n",
      "  [ 0.13301275  0.03876761  0.3893269  -0.13670559  0.01594416  0.2155036\n",
      "   -0.12713672  0.10729144]\n",
      "  [ 0.02745996  0.30632418  0.16741854  0.20429557 -0.70107592 -0.12831244\n",
      "    0.11187645  0.14846776]\n",
      "  [-0.14946871  0.77651069 -0.08323978 -0.33023814  0.10181465 -0.12570022\n",
      "    0.53156383  0.09148759]\n",
      "  [-0.00102579  0.23840434  0.25152227  0.44908708  0.07410748  0.08185614\n",
      "    0.2105041   0.12147649]]]\n",
      "Output weights: [[ 0.38534     0.18173763]\n",
      " [-0.38299172  0.17500083]\n",
      " [ 0.92322945  0.26723145]\n",
      " [-0.15384041  0.25155382]\n",
      " [-0.26992483 -0.15037114]\n",
      " [-0.14226157  0.18722585]\n",
      " [ 0.91542787  0.78004026]\n",
      " [ 0.16084336 -0.76261095]]\n",
      "Error=0.019992277324741268, current learning rate=0.0008503097019926455\n",
      "Error=7.468906086305142e-08, current learning rate=0.00042515485099632274\n",
      "[ 0.08856378  0.91134818]\n",
      "[ 0.17809367  0.82129001]\n",
      "[ 0.98555297  0.01446989]\n",
      "[ 0.99738733  0.00264264]\n",
      "[ 0.98555297  0.01446989]\n",
      "[  9.99739533e-01   2.73662445e-04]\n",
      "[ 0.98579839  0.01423065]\n",
      "[ 0.08785425  0.91202532]\n",
      "[ 0.43409119  0.56390649]\n",
      "[ 0.96224111  0.03787972]\n",
      "[ 0.99269007  0.00721322]\n",
      "[ 0.97082114  0.029901  ]\n",
      "[ 0.98681543  0.0134102 ]\n",
      "[ 0.0839324   0.91576624]\n",
      "[ 0.98491115  0.01537551]\n",
      "[ 0.99732673  0.00270555]\n",
      "[ 0.96224111  0.03787972]\n",
      "[ 0.9966655   0.00333296]\n",
      "[ 0.99864926  0.00133769]\n",
      "[ 0.09985779  0.90001456]\n",
      "[ 0.10791849  0.89171552]\n",
      "[ 0.8243768  0.1732602]\n",
      "[ 0.98029278  0.02015105]\n",
      "[ 0.96770913  0.03126137]\n",
      "[  9.99759601e-01   2.39789144e-04]\n",
      "[ 0.13319152  0.8664654 ]\n",
      "[  9.99885042e-01   1.18333138e-04]\n",
      "[ 0.97069389  0.03013377]\n",
      "[ 0.9966655   0.00333296]\n",
      "[ 0.09303807  0.90678877]\n",
      "[ 0.99604103  0.0038421 ]\n",
      "[ 0.10274503  0.89702088]\n",
      "[  9.99759601e-01   2.39789144e-04]\n",
      "[  9.99449323e-01   5.65450435e-04]\n",
      "[ 0.99505583  0.00502185]\n",
      "[ 0.84978581  0.14691278]\n",
      "[ 0.09940342  0.90014578]\n",
      "[ 0.9966655   0.00333296]\n",
      "[ 0.08134694  0.91842917]\n",
      "[ 0.95219235  0.04768664]\n",
      "[ 0.08045713  0.91961195]\n",
      "[ 0.98555297  0.01446989]\n",
      "[ 0.97437244  0.02573029]\n",
      "[ 0.47815962  0.5235406 ]\n",
      "[ 0.92099139  0.07949412]\n",
      "[ 0.99732673  0.00270555]\n",
      "[ 0.97627641  0.02367795]\n",
      "[ 0.99505583  0.00502185]\n",
      "[ 0.02310339  0.97812743]\n",
      "[ 0.99444932  0.0055342 ]\n",
      "[ 0.12985019  0.86931555]\n",
      "[ 0.08556537  0.91433856]\n",
      "[ 0.10140364  0.8984982 ]\n",
      "[ 0.08692811  0.91304255]\n",
      "[ 0.40060723  0.59976405]\n",
      "[ 0.99849668  0.00149727]\n",
      "[ 0.95228428  0.04896588]\n",
      "[ 0.93445205  0.06728982]\n",
      "[ 0.14149891  0.85866319]\n",
      "[ 0.08651335  0.91323429]\n",
      "[ 0.97437244  0.02573029]\n",
      "[ 0.10167588  0.89815932]\n",
      "[ 0.98555297  0.01446989]\n",
      "[  9.99739533e-01   2.73662445e-04]\n",
      "[ 0.99248758  0.00750687]\n",
      "[ 0.08792354  0.9120288 ]\n",
      "[ 0.99864926  0.00133769]\n",
      "[ 0.96134215  0.03883974]\n",
      "[ 0.08380835  0.91609211]\n",
      "[  9.99759601e-01   2.39789144e-04]\n",
      "[ 0.93278633  0.06741836]\n",
      "[ 0.55293092  0.4455934 ]\n",
      "[ 0.08823113  0.91165758]\n",
      "[ 0.0940035   0.90594764]\n",
      "[ 0.42513132  0.57279242]\n",
      "[ 0.07902865  0.92076964]\n",
      "[ 0.8288827   0.16992111]\n",
      "[ 0.9966655   0.00333296]\n",
      "[ 0.99476268  0.00515327]\n",
      "[ 0.99505583  0.00502185]\n",
      "[ 0.95228428  0.04896588]\n",
      "[ 0.99894312  0.00106761]\n",
      "[ 0.96546903  0.034699  ]\n",
      "[ 0.93278633  0.06741836]\n",
      "[ 0.98778024  0.01224821]\n",
      "[ 0.1304638   0.86900073]\n",
      "[ 0.99864926  0.00133769]\n",
      "[ 0.25307934  0.74414889]\n",
      "[ 0.98555297  0.01446989]\n",
      "[ 0.99864926  0.00133769]\n",
      "[ 0.11028582  0.88955228]\n",
      "[ 0.08757224  0.91229209]\n",
      "[ 0.89375971  0.10490151]\n",
      "[ 0.98555297  0.01446989]\n",
      "[ 0.92170539  0.07782875]\n",
      "[ 0.08785721  0.91211354]\n",
      "[ 0.73713603  0.26418444]\n",
      "[ 0.99837383  0.00166515]\n",
      "[ 0.09179919  0.90818057]\n",
      "[  9.99885042e-01   1.18333138e-04]\n",
      "[ 0.94365601  0.05625551]\n",
      "[ 0.08529552  0.91453283]\n",
      "[ 0.96546903  0.034699  ]\n",
      "[ 0.98969041  0.00982695]\n",
      "[ 0.99732673  0.00270555]\n",
      "[  9.99918052e-01   8.46678139e-05]\n",
      "[ 0.9930228   0.00709867]\n",
      "[ 0.99864926  0.00133769]\n",
      "[ 0.96669338  0.03339511]\n",
      "[  9.99759601e-01   2.39789144e-04]\n",
      "[ 0.20233787  0.79643921]\n",
      "[ 0.9930228   0.00709867]\n",
      "[ 0.13231565  0.86721554]\n",
      "[ 0.99098605  0.00912148]\n",
      "[ 0.97627641  0.02367795]\n",
      "[ 0.65306144  0.34522113]\n",
      "[ 0.84600875  0.15442429]\n",
      "[ 0.08062531  0.91915095]\n",
      "[ 0.09008358  0.90983363]\n",
      "[ 0.09783111  0.90208159]\n",
      "[ 0.93278633  0.06741836]\n",
      "[ 0.08738611  0.91258152]\n",
      "[ 0.99438397  0.00546409]\n",
      "[ 0.09500496  0.90493058]\n",
      "[ 0.18379749  0.81554429]\n",
      "[ 0.90719536  0.09317389]\n",
      "[ 0.39198188  0.60569338]\n",
      "[ 0.77682093  0.22413825]\n",
      "[  9.99739533e-01   2.73662445e-04]\n",
      "[ 0.08281093  0.91704446]\n",
      "[ 0.08706193  0.91297354]\n",
      "[ 0.96759749  0.03350526]\n",
      "[ 0.9098324   0.09035723]\n",
      "[ 0.97894783  0.02071079]\n",
      "[ 0.9300963   0.07041861]\n",
      "[  9.99759601e-01   2.39789144e-04]\n",
      "[ 0.96365903  0.03645444]\n",
      "[  9.99981394e-01   1.92102739e-05]\n",
      "[ 0.07735124  0.92268528]\n",
      "[ 0.9872941   0.01221503]\n",
      "[ 0.09582083  0.90410253]\n",
      "[ 0.08312986  0.91675349]\n",
      "[ 0.13463642  0.86522676]\n",
      "[ 0.10086918  0.89882782]\n",
      "[ 0.92099139  0.07949412]\n",
      "[ 0.9098324   0.09035723]\n",
      "[ 0.13800582  0.86174967]\n",
      "[ 0.08229817  0.91757845]\n",
      "[ 0.08343067  0.91646695]\n",
      "[ 0.9098324   0.09035723]\n",
      "[ 0.99864926  0.00133769]\n",
      "[ 0.16060469  0.8389042 ]\n",
      "[ 0.85415815  0.1438308 ]\n",
      "[  9.99759601e-01   2.39789144e-04]\n",
      "[ 0.99864926  0.00133769]\n",
      "[  9.99739533e-01   2.73662445e-04]\n",
      "[ 0.98380983  0.01633034]\n",
      "[ 0.09138987  0.90856903]\n",
      "[ 0.97231771  0.02785329]\n",
      "[ 0.12082057  0.87849383]\n",
      "[ 0.99864926  0.00133769]\n",
      "[ 0.97437244  0.02573029]\n",
      "[  9.99999931e-01   7.22136643e-08]\n",
      "[ 0.99663433  0.00334117]\n",
      "[ 0.99900109  0.0010049 ]\n",
      "[ 0.09654546  0.90322637]\n",
      "[ 0.08070403  0.91913589]\n",
      "[ 0.08286296  0.91690492]\n",
      "[ 0.08123049  0.91862093]\n",
      "[ 0.93278633  0.06741836]\n",
      "[ 0.98579839  0.01423065]\n",
      "[ 0.74963917  0.2533224 ]\n",
      "[ 0.96224111  0.03787972]\n",
      "[ 0.07892875  0.92086625]\n",
      "[ 0.99732673  0.00270555]\n",
      "[  9.99759601e-01   2.39789144e-04]\n",
      "[ 0.12394792  0.87579917]\n",
      "[ 0.27761139  0.72206117]\n",
      "[ 0.97894783  0.02071079]\n",
      "[ 0.95865007  0.04148058]\n",
      "[ 0.98555297  0.01446989]\n",
      "[ 0.0942342   0.90569646]\n",
      "[  9.99981394e-01   1.92102739e-05]\n",
      "[ 0.0936337   0.90626628]\n",
      "[ 0.98555297  0.01446989]\n",
      "[ 0.12940533  0.87093478]\n",
      "[ 0.99810593  0.0018338 ]\n",
      "[ 0.19804073  0.80121238]\n",
      "[ 0.99900109  0.0010049 ]\n",
      "[ 0.99900109  0.0010049 ]\n",
      "[ 0.97437244  0.02573029]\n",
      "[ 0.99894312  0.00106761]\n",
      "[ 0.83243519  0.16388783]\n",
      "[ 0.99684546  0.00313222]\n",
      "[  9.99759601e-01   2.39789144e-04]\n",
      "[ 0.08242907  0.91744266]\n",
      "[ 0.17221152  0.82723679]\n",
      "[ 0.10140364  0.8984982 ]\n",
      "[ 0.8966213   0.10365458]\n",
      "[ 0.99444932  0.0055342 ]\n",
      "[  9.99759601e-01   2.39789144e-04]\n",
      "[ 0.1069656   0.89288875]\n",
      "[ 0.98555297  0.01446989]\n",
      "[ 0.97160457  0.02826999]\n",
      "[ 0.2232699   0.77397158]\n",
      "[ 0.13119097  0.86814589]\n",
      "[ 0.09425582  0.90555947]\n",
      "[ 0.08606871  0.91388548]\n",
      "[ 0.97437244  0.02573029]\n",
      "[ 0.9930228   0.00709867]\n",
      "[ 0.93820677  0.06102868]\n",
      "[ 0.9300963   0.07041861]\n",
      "[ 0.99081239  0.00921037]\n",
      "[ 0.78048832  0.22320634]\n",
      "[ 0.08290656  0.91688207]\n",
      "[ 0.11050316  0.88928798]\n",
      "[ 0.08101701  0.9187772 ]\n",
      "[ 0.23952017  0.75958072]\n",
      "[ 0.08738854  0.91227882]\n",
      "[ 0.99864926  0.00133769]\n",
      "[ 0.97254936  0.02710688]\n",
      "[ 0.93278633  0.06741836]\n",
      "[ 0.41188721  0.58681334]\n",
      "[ 0.98857002  0.01157789]\n",
      "[ 0.09734677  0.90225311]\n",
      "[ 0.68358168  0.31794936]\n",
      "[ 0.09094702  0.90889279]\n",
      "[  9.99759601e-01   2.39789144e-04]\n",
      "Accuracy: 0.6491, precision: 0.6491, recall: 0.6491, F1: 0.6491\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(45)\n",
    "nn = NeuralNetwork(8, (1, 8), 2, learnRate=1/np.sqrt(data.shape[0]))\n",
    "# xTrain = xTrain[:10]\n",
    "# yTrain = yTrain[:10]\n",
    "nn.fit(xTrain, yTrain)\n",
    "accuracy, precision, recall, f1 = nn.score(xTest, yTest)\n",
    "print('Accuracy: {:.4f}, precision: {:.4f}, recall: {:.4f}, F1: {:.4f}'.format(\n",
    "        accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
